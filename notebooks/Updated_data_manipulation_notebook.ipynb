{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.13; rv:10.0) Gecko/20100101 Firefox/10.0'}\n",
    "url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'\n",
    "resp = requests.get(url, headers=headers)\n",
    "file_object = io.StringIO(resp.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_object, \n",
    "                     index_col = ['date'],\n",
    "                     parse_dates = True, \n",
    "                     usecols=[\"date\", \"iso_code\", \"location\", \n",
    "                              \"population\", \"continent\",\n",
    "                              \"total_cases\", \"total_deaths\"]).rename(\n",
    "    columns = {'iso_code': 'country_code', 'location': 'country_name'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare metadata from World Bank\n",
    "metadata = pd.read_csv(\"https://raw.githubusercontent.com/hongtaoh/covid19-data/master/data_sources/metadata/worldbank/country_metadata.csv\",\n",
    "                      usecols=[\"Country Code\", \"Region\"]).rename(\n",
    "    columns = {'Country Code': 'country_code', 'Region': 'world_region'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = pd.date_range(df.index.min(), df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fallBehind_place_date_dateframe(df): # input should be df\n",
    "    fallBehind_place_list = []\n",
    "    fallBehind_last_date_available_list = []\n",
    "    fallBehind_last_date_index_list = []\n",
    "    for group in df.groupby(\"country_code\"):\n",
    "        if group[1].tail(1).index != df.index.max():\n",
    "            fallBehind_place_list.append(group[0])\n",
    "    for p in fallBehind_place_list:\n",
    "        fallBehind_last_date_index_list.append(all_dates.get_loc(\n",
    "            df[df.loc[:, 'country_code']== p].index[-1].strftime(\"%Y-%m-%d\")))\n",
    "        fallBehind_last_date_available_list.append(\n",
    "            df[df.loc[:, 'country_code']== p].index[-1].strftime(\"%Y-%m-%d\"))\n",
    "    d = {'fallBehind_place': fallBehind_place_list, \n",
    "         'fallBehind_last_date_available': fallBehind_last_date_available_list,\n",
    "         'fallBehind_last_date_index': fallBehind_last_date_index_list}\n",
    "    fallBehind_list = pd.DataFrame(data = d)\n",
    "    return fallBehind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fallBehind_place</th>\n",
       "      <th>fallBehind_last_date_available</th>\n",
       "      <th>fallBehind_last_date_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIA</td>\n",
       "      <td>2021-02-13</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALB</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AND</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>WSM</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>YEM</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ZAF</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fallBehind_place fallBehind_last_date_available  \\\n",
       "0                AFG                     2021-02-18   \n",
       "1                AGO                     2021-02-18   \n",
       "2                AIA                     2021-02-13   \n",
       "3                ALB                     2021-02-18   \n",
       "4                AND                     2021-02-18   \n",
       "..               ...                            ...   \n",
       "207              WSM                     2021-02-18   \n",
       "208              YEM                     2021-02-18   \n",
       "209              ZAF                     2021-02-18   \n",
       "210              ZMB                     2021-02-18   \n",
       "211              ZWE                     2021-02-18   \n",
       "\n",
       "     fallBehind_last_date_index  \n",
       "0                           414  \n",
       "1                           414  \n",
       "2                           409  \n",
       "3                           414  \n",
       "4                           414  \n",
       "..                          ...  \n",
       "207                         414  \n",
       "208                         414  \n",
       "209                         414  \n",
       "210                         414  \n",
       "211                         414  \n",
       "\n",
       "[212 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fallBehind_list = get_fallBehind_place_date_dateframe(df)\n",
    "fallBehind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cntry_dfs(df): \n",
    "    dfs = []\n",
    "    for group in df.groupby(\"country_code\"):\n",
    "        cntry_df = (\n",
    "            group[1].reindex(all_dates, method=\"pad\")\n",
    "        )\n",
    "        cntry_df[\"total_cases\"] = cntry_df[\"total_cases\"]\n",
    "        cntry_df[\"total_deaths\"] = cntry_df[\"total_deaths\"]\n",
    "        cntry_df[\"country_code\"] = group[0]\n",
    "        cntry_df[\"country_name\"] = group[1][\"country_name\"][-1]\n",
    "        cntry_df[\"continent\"] = group[1][\"continent\"][-1]\n",
    "        cntry_df[\"population\"] = group[1][\"population\"][-1]\n",
    "        dfs.append(\n",
    "            cntry_df\n",
    "        )\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = extract_cntry_dfs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_first_case_death_with_zero(df): # input is dfs\n",
    "    for i in np.arange(0, len(df)):\n",
    "        if (df[i].head(1).total_cases.isnull()[0] & df[i].head(1).total_deaths.isnull()[0]):\n",
    "            df[i][0:1] = [df[i].country_code[-1],\n",
    "            df[i].continent[-1],\n",
    "            df[i].country_name[-1],\n",
    "            0,\n",
    "            0, \n",
    "            df[i].population[-1]\n",
    "            ]\n",
    "        if (df[i].head(1).total_cases.isnull()[0] & df[i].head(1).total_deaths.notnull()[0]):\n",
    "            df[i][0:1] = [df[i].country_code[-1],\n",
    "            df[i].continent[-1],\n",
    "            df[i].country_name[-1],\n",
    "            0,\n",
    "            df[i].total_deaths[0],\n",
    "            df[i].population[-1]\n",
    "            ]\n",
    "        if (df[i].head(1).total_cases.notnull()[0] & df[i].head(1).total_deaths.isnull()[0]):\n",
    "            df[i][0:1] = [df[i].country_code[-1],\n",
    "            df[i].continent[-1],\n",
    "            df[i].country_name[-1],\n",
    "            df[i].total_cases[0],\n",
    "            0,\n",
    "            df[i].population[-1]\n",
    "            ]\n",
    "    return df # output is the dfs with first case & death conditionally filled with zero. \n",
    "              # Later, I name this output to be \"dfs_first_zero_filled\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_first_zero_filled = fill_first_case_death_with_zero(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AIA', 'GGY', 'JEY', 'OWID_AFR', 'OWID_ASI', 'OWID_EUN',\n",
       "       'OWID_EUR', 'OWID_INT', 'OWID_NAM', 'OWID_NCY', 'OWID_OCE',\n",
       "       'OWID_SAM', 'WLD', 'SHN', 'TWN', 'VAT'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df = pd.concat(dfs_first_zero_filled).fillna(method=\"ffill\").reset_index().rename(\n",
    "        columns={\"index\": \"date\"})\n",
    "    #To change the original country codes of \"KOS\" and World to match metadata from WB:\n",
    "concat_df.loc[(concat_df.country_code == \"OWID_KOS\"), ('country_code')] = \"XKX\"\n",
    "concat_df.loc[(concat_df.country_code == \"OWID_WRL\"), ('country_code')] = \"WLD\"\n",
    "    # To get the column of \"world_region\" in concat_df by merging with WB metadata\n",
    "left_join_df = pd.merge(concat_df, metadata, on = \"country_code\", how = \"left\")\n",
    "# df[df['name column'].isnull()]\n",
    "left_join_df.loc[left_join_df.world_region.isnull()].country_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_meta(df): #input should be dfs_first_zero_filled\n",
    "    concat_df = pd.concat(df).fillna(method=\"ffill\").reset_index().rename(\n",
    "        columns={\"index\": \"date\"})\n",
    "    #To change the original country codes of \"KOS\" and World to match metadata from WB:\n",
    "    concat_df.loc[(concat_df.country_code == \"OWID_KOS\"), ('country_code')] = \"XKX\"\n",
    "    concat_df.loc[(concat_df.country_code == \"OWID_WRL\"), ('country_code')] = \"WLD\"\n",
    "    # To get the column of \"world_region\" in concat_df by merging with WB metadata\n",
    "    left_join_df = pd.merge(concat_df, metadata, on = \"country_code\", how = \"left\")\n",
    "    left_join_df.loc[:,'date'] = left_join_df.loc[:,'date'].dt.strftime('%Y-%m-%d')\n",
    "    left_join_df.loc[(left_join_df.country_code == \"AIA\"), ('world_region')] = \"Latin America & Caribbean\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"BES\"), ('world_region')] = \"Latin America & Caribbean\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"ESH\"), ('world_region')] = \"Middle East & North Africa\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"FLK\"), ('world_region')] = \"Latin America & Caribbean\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"GGY\"), ('world_region')] = \"Europe & Central Asia\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"JEY\"), ('world_region')] = \"Europe & Central Asia\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"MSR\"), ('world_region')] = \"Latin America & Caribbean\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"TWN\"), ('world_region')] = \"East Asia & Pacific\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"VAT\"), ('world_region')] = \"Europe & Central Asia\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"WLF\"), ('world_region')] = \"East Asia & Pacific\"\n",
    "    left_join_df.loc[(left_join_df.country_code == \"WLD\"), ('world_region')] = \"World\"\n",
    "    return left_join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_join_df = merge_with_meta(dfs_first_zero_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following step, I converted \n",
    "def fallBehind_filled_to_null (df): # input should be left_join_df\n",
    "    left_join_copy_group1_with_nan = []\n",
    "    for group in df.groupby('country_code'):\n",
    "        for i in np.arange(0, len(fallBehind_list)):\n",
    "            if group[1].tail(1).country_code.iloc[0] == fallBehind_list.iloc[i, 0]:\n",
    "                group[1].tail(len(all_dates) - 1 - fallBehind_list.iloc[i, 2]).total_cases = np.nan\n",
    "                group[1].tail(len(all_dates) - 1 - fallBehind_list.iloc[i, 2]).total_deaths = np.nan\n",
    "        left_join_copy_group1_with_nan.append(group[1])\n",
    "    left_join_copy_group1_with_nan_concated = pd.concat(left_join_copy_group1_with_nan)\n",
    "    left_join_copy_group1_concated_with_null = left_join_copy_group1_with_nan_concated\n",
    "    left_join_copy_group1_concated_with_null.replace(np.nan, 'null', inplace=True)\n",
    "    return left_join_copy_group1_concated_with_null \n",
    "# Later, I'll name the output to be fallBehind_with_nan_concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fallBehind_with_nan_concated = fallBehind_filled_to_nan(left_join_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dviz/lib/python3.8/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "fallBehind_with_null = fallBehind_filled_to_null(left_join_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fallBehind_with_null.replace(np.nan, 'null', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fallBehind_with_null[fallBehind_with_null.loc[:, 'country_code'] == 'BEL'].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fallBehind_nan_changed[fallBehind_nan_changed.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>country_name</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>population</th>\n",
       "      <th>world_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76534</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>600244</td>\n",
       "      <td>12326</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76535</th>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>604577</td>\n",
       "      <td>12370</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76536</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>608411</td>\n",
       "      <td>12428</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76537</th>\n",
       "      <td>2021-02-13</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>608411</td>\n",
       "      <td>12428</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76538</th>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>608411</td>\n",
       "      <td>12428</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76539</th>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>608411</td>\n",
       "      <td>12428</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76540</th>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>617869</td>\n",
       "      <td>12487</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76541</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>622102</td>\n",
       "      <td>12569</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76542</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>627022</td>\n",
       "      <td>12598</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76543</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>SWE</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>10099270.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date country_code continent country_name total_cases  \\\n",
       "76534  2021-02-10          SWE    Europe       Sweden      600244   \n",
       "76535  2021-02-11          SWE    Europe       Sweden      604577   \n",
       "76536  2021-02-12          SWE    Europe       Sweden      608411   \n",
       "76537  2021-02-13          SWE    Europe       Sweden      608411   \n",
       "76538  2021-02-14          SWE    Europe       Sweden      608411   \n",
       "76539  2021-02-15          SWE    Europe       Sweden      608411   \n",
       "76540  2021-02-16          SWE    Europe       Sweden      617869   \n",
       "76541  2021-02-17          SWE    Europe       Sweden      622102   \n",
       "76542  2021-02-18          SWE    Europe       Sweden      627022   \n",
       "76543  2021-02-19          SWE    Europe       Sweden        null   \n",
       "\n",
       "      total_deaths  population           world_region  \n",
       "76534        12326  10099270.0  Europe & Central Asia  \n",
       "76535        12370  10099270.0  Europe & Central Asia  \n",
       "76536        12428  10099270.0  Europe & Central Asia  \n",
       "76537        12428  10099270.0  Europe & Central Asia  \n",
       "76538        12428  10099270.0  Europe & Central Asia  \n",
       "76539        12428  10099270.0  Europe & Central Asia  \n",
       "76540        12487  10099270.0  Europe & Central Asia  \n",
       "76541        12569  10099270.0  Europe & Central Asia  \n",
       "76542        12598  10099270.0  Europe & Central Asia  \n",
       "76543         null  10099270.0  Europe & Central Asia  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fallBehind_with_null[fallBehind_with_null.loc[:, 'country_code'] == 'SWE'].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_structure(df, gby=\"country_code\"): # input should be fallBehind_with_null\n",
    "    data = []\n",
    "    for g in df.groupby([gby]):\n",
    "        code = g[0]\n",
    "        cntry_df = g[1]\n",
    "        try:\n",
    "            country_data = {\n",
    "                \"country_code\": code,\n",
    "                \"country_name\": cntry_df.loc[:,\"country_name\"].iloc[0],\n",
    "                \"population\": cntry_df.loc[:,\"population\"].iloc[0],\n",
    "                \"region\": cntry_df.loc[:,\"world_region\"].iloc[0],\n",
    "                \"confirmed\": list(zip(cntry_df.date, cntry_df.total_cases)),\n",
    "                \"deaths\": list(zip(cntry_df.date, cntry_df.total_deaths)),\n",
    "            }\n",
    "            data.append(country_data)\n",
    "        except KeyError:\n",
    "            print(\"metadata doesn't exist for: \", code)\n",
    "            continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data_structure(fallBehind_with_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3740598"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"../output/cntry_stat_owid.json\", \"w\").write(json.dumps(data, separators=(\",\", \":\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dviz",
   "language": "python",
   "name": "dviz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
